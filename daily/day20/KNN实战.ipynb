{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取Facebook位置数据集...\n",
      "将time列转换为年月日时分秒格式...\n",
      "从时间中提取星期几、小时和分钟作为新特征...\n",
      "数据集基本信息：\n",
      "样本数量: 29118021\n",
      "特征数量: 10\n",
      "数据集fb_train的类型： <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "数据集的前5行:\n",
      "   row_id       x       y  accuracy    time    place_id      time_formatted  \\\n",
      "0       0  0.7941  9.0809        54  470702  8523065625 1970-01-06 10:45:02   \n",
      "1       1  5.9567  4.7968        13  186555  1757726713 1970-01-03 03:49:15   \n",
      "2       2  8.3078  7.0407        74  322648  1137537235 1970-01-04 17:37:28   \n",
      "3       3  7.3665  2.5165        65  704587  6567393236 1970-01-09 03:43:07   \n",
      "4       4  4.0961  1.1307        31  472130  7440663949 1970-01-06 11:08:50   \n",
      "\n",
      "   weekday  hour  day  \n",
      "0        1    10    6  \n",
      "1        5     3    3  \n",
      "2        6    17    4  \n",
      "3        4     3    9  \n",
      "4        1    11    6  \n"
     ]
    }
   ],
   "source": [
    "# 读取Facebook位置数据集\n",
    "print(\"读取Facebook位置数据集...\")\n",
    "fb_train = pd.read_csv('C:\\\\Users\\\\19942\\\\Desktop\\\\wangdao\\\\code\\\\python_ml\\\\data\\\\FBlocation\\\\train.csv')\n",
    "\n",
    "\n",
    "# 相比x，y，准确性和地点id，使用时间特征更能提高模型准确性，对时间进行细分\n",
    "\n",
    "# 将time列转换为年月日时分秒格式\n",
    "print(\"将time列转换为年月日时分秒格式...\")\n",
    "# 假设time以秒为单位，转换为时间格式（to_datetime)，并添加为新列time_formatted\n",
    "fb_train['time_formatted'] = pd.to_datetime(fb_train['time'], unit='s')\n",
    "\n",
    "# 从time_formatted提取以下特征:\n",
    "# 星期几(dt.dayofweek)、小时(dt.hour)和天(dt.day)\n",
    "print(\"从时间中提取星期几、小时和分钟作为新特征...\")\n",
    "fb_train['weekday'] = fb_train['time_formatted'].dt.dayofweek  # 星期几 (0-6, 0是星期一)\n",
    "fb_train['hour'] = fb_train['time_formatted'].dt.hour  # 小时 (0-23)\n",
    "fb_train['day'] = fb_train['time_formatted'].dt.day  # 天\n",
    "\n",
    "# 显示数据集基本信息\n",
    "print(\"数据集基本信息：\")\n",
    "print(f\"样本数量: {fb_train.shape[0]}\")\n",
    "print(f\"特征数量: {fb_train.shape[1]}\")\n",
    "print('数据集fb_train的类型：',type(fb_train))\n",
    "print(\"\\n数据集的前5行:\")\n",
    "print(fb_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "检查缺失值:\n",
      "row_id            0\n",
      "x                 0\n",
      "y                 0\n",
      "accuracy          0\n",
      "time              0\n",
      "place_id          0\n",
      "time_formatted    0\n",
      "weekday           0\n",
      "hour              0\n",
      "day               0\n",
      "dtype: int64\n",
      "筛选后的样本数量: 17710\n",
      "筛选前的样本数量: 29118021\n",
      "筛选比例: 0.06%\n",
      "\n",
      "统计每个place_id的出现次数...\n",
      "去除place_id出现次数小于等于3的数据...\n",
      "去除后的样本数量: 16918\n",
      "去除的样本比例: 99.94%\n",
      "剩余的不同place_id数量: 239\n",
      "\n",
      "过滤后的训练集（filter_fb_train）的部分信息：\n",
      "       row_id       x       y  accuracy    time    place_id  \\\n",
      "600      600  1.2214  2.7023        17   65380  6683426742   \n",
      "957      957  1.1832  2.6891        58  785470  6683426742   \n",
      "4345    4345  1.1935  2.6550        11  400082  6889790653   \n",
      "4735    4735  1.1452  2.6074        49  514983  6822359752   \n",
      "5580    5580  1.0089  2.7287        19  732410  1527921905   \n",
      "\n",
      "          time_formatted  weekday  hour  day  \n",
      "600  1970-01-01 18:09:40        3    18    1  \n",
      "957  1970-01-10 02:11:10        5     2   10  \n",
      "4345 1970-01-05 15:08:02        0    15    5  \n",
      "4735 1970-01-06 23:03:03        1    23    6  \n",
      "5580 1970-01-09 11:26:50        4    11    9  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 检查缺失值\n",
    "print(\"\\n检查缺失值:\")\n",
    "print(fb_train.isnull().sum())      # 如果有缺失，用SimpleImputer替换\n",
    "\n",
    "\n",
    "# 对x和y的数值范围进行筛选\n",
    "# 筛选出x在1.0到1.25之间，y在2.5到2.75之间的数据\n",
    "filtered_fb_train=fb_train.query(\"x > 1.0 &  x < 1.25 & y > 2.5 & y < 2.75\")\n",
    "print(f\"筛选后的样本数量: {filtered_fb_train.shape[0]}\")\n",
    "print(f\"筛选前的样本数量: {fb_train.shape[0]}\")\n",
    "print(f\"筛选比例: {filtered_fb_train.shape[0]/fb_train.shape[0]:.2%}\")\n",
    "\n",
    "# 对place_id进行筛选，过滤掉出现次数小于3的place（冷门地点）\n",
    "# 统计每个place_id的出现次数\n",
    "print(\"\\n统计每个place_id的出现次数...\")\n",
    "place_counts = filtered_fb_train['place_id'].value_counts()\n",
    "\n",
    "# 找出出现次数大于3的place_id\n",
    "valid_places = place_counts[place_counts > 3].index\n",
    "\n",
    "# 只保留出现次数大于3的place_id对应的数据\n",
    "print(\"去除place_id出现次数小于等于3的数据...\")\n",
    "filtered_fb_train = filtered_fb_train[filtered_fb_train['place_id'].isin(valid_places)]\n",
    "\n",
    "\n",
    "print(f\"去除后的样本数量: {filtered_fb_train.shape[0]}\")\n",
    "print(f\"去除的样本比例: {1 - filtered_fb_train.shape[0]/fb_train.shape[0]:.2%}\")\n",
    "print(f\"剩余的不同place_id数量: {filtered_fb_train['place_id'].nunique()}\")\n",
    "\n",
    "print('\\n过滤后的训练集（filter_fb_train）的部分信息：\\n',filtered_fb_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "划分训练集和验证集...\n",
      "测试集X_train的前5行：\n",
      "                x       y  accuracy  weekday  hour  day\n",
      "5409451   1.0850  2.6961        62        5     0    3\n",
      "24956130  1.1627  2.6654        43        1    13    6\n",
      "25705982  1.0108  2.5411       165        5     0    3\n",
      "8937451   1.1814  2.5099        38        3     5    8\n",
      "18299121  1.2061  2.5105        57        3    21    8\n",
      "\n",
      "对特征进行标准化处理...\n",
      "Facebook位置数据集划分结果：\n",
      "训练集样本数量: 13534\n",
      "验证集样本数量: 3384\n",
      "特征数量: 6\n",
      "\n",
      "标签(place_id)的数量(unique): 239\n",
      "\n",
      "数据预处理完成，可以进行KNN训练\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.48293676,  0.90291955, -0.17915424,  1.13044561, -1.65117484,\n",
       "        -0.76794871],\n",
       "       [ 0.52467098,  0.46434201, -0.35200665, -1.25794776,  0.2182894 ,\n",
       "         0.33718539],\n",
       "       [-1.44515676, -1.31139703,  0.75788777,  1.13044561, -1.65117484,\n",
       "        -0.76794871],\n",
       "       [ 0.76717117, -1.75711752, -0.39749413, -0.06375108, -0.93215013,\n",
       "         1.07394146],\n",
       "       [ 1.0874789 , -1.74854597, -0.22464172, -0.06375108,  1.36872893,\n",
       "         1.07394146]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 提取特征和标签，加入新提取的时间特征，然后指定标签(place_id)\n",
    "\n",
    "X = filtered_fb_train[['x', 'y', 'accuracy', 'weekday', 'hour', 'day']]  # 特征\n",
    "y = filtered_fb_train['place_id']  # 把place_id作为标签\n",
    "# 划分训练集和验证集\n",
    "print(\"\\n划分训练集和验证集...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print('测试集X_train的前5行：\\n',X_train.head(5))\n",
    "\n",
    "# 特征标准化 - 使用训练集拟合标准化器，然后分别转换训练集和验证集\n",
    "print(\"\\n对特征进行标准化处理...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # 对训练集进行fit和transform\n",
    "X_val_scaled = scaler.transform(X_val)  # 对验证集只进行transform\n",
    "\n",
    "# 打印数据集划分结果\n",
    "print(\"Facebook位置数据集划分结果：\")\n",
    "print(f\"训练集样本数量: {X_train.shape[0]}\")\n",
    "print(f\"验证集样本数量: {X_val.shape[0]}\")\n",
    "print(f\"特征数量: {X_train.shape[1]}\")\n",
    "\n",
    "# 统计标签数量\n",
    "print(\"\\n标签(place_id)的数量(unique):\", y.nunique())\n",
    "\n",
    "print(\"\\n数据预处理完成，可以进行KNN训练\")\n",
    "\n",
    "X_train_scaled[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练、评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练KNN模型...\n",
      "KNN模型训练和评估总耗时: 0.02 秒\n",
      "KNN模型准确率: 0.4805\n",
      "\n",
      "KNN模型训练和评估完成！\n"
     ]
    }
   ],
   "source": [
    "# 导入KNN分类器和评估指标\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import time\n",
    "\n",
    "print(\"开始训练KNN模型...\")\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 创建KNN分类器，使用默认K=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# 训练模型\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "print(f\"KNN模型训练和评估总耗时: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "\n",
    "# 在验证集上进行预测\n",
    "y_pred = knn.predict(X_val_scaled)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"KNN模型准确率: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nKNN模型训练和评估完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用网格搜索，对超参数进行调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始使用GridSearchCV进行KNN参数优化...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\py\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "网格搜索完成，耗时: 6.96 秒\n",
      "最佳参数: {'n_neighbors': 11, 'weights': 'distance'}\n",
      "交叉验证最佳得分: 0.4885\n"
     ]
    }
   ],
   "source": [
    "# 导入GridSearchCV和交叉验证相关工具\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "print(\"开始使用GridSearchCV进行KNN参数优化...\")\n",
    "\n",
    "\n",
    "# 设置开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# 创建KNN分类器\n",
    "# 会爆出警告，因为可能有一个特征的样本太少，无法计算邻居\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 创建GridSearchCV对象\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=knn,              # 要优化的基础KNN分类器\n",
    "    param_grid=param_grid,      # 超参数搜索空间\n",
    "    cv=3,                       # 3折交叉验证\n",
    "    scoring='accuracy',         # 以准确率accuracy作为评估指标\n",
    "    n_jobs=-1                   # 并行使用所有可以使用的CPU核心(-1)\n",
    ")\n",
    "\n",
    "# 在训练集上拟合网格搜索，这个过程会对特征自动训练不需要knn.fit\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 获取最佳参数和最佳得分\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "\n",
    "# 计算结束时间\n",
    "end_time = time.time()\n",
    "time_used = end_time - start_time\n",
    "\n",
    "# 输出结果\n",
    "print(f\"\\n网格搜索完成，耗时: {time_used:.2f} 秒\")\n",
    "print(f\"最佳参数: {best_params}\")\n",
    "print(f\"交叉验证最佳得分: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳模型在验证集上的准确率: 0.5003\n"
     ]
    }
   ],
   "source": [
    "# 使用最佳参数构建模型\n",
    "# best_knn = KNeighborsClassifier(**best_params)\n",
    "# best_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 不需要重新构建和训练模型，GridSearchCV已经用最优参数在fit时训练好了模型\n",
    "best_knn = grid_search.best_estimator_\n",
    "\n",
    "# 在验证集上评估最佳模型\n",
    "y_pred_best = best_knn.predict(X_val_scaled)\n",
    "best_accuracy = accuracy_score(y_val, y_pred_best)\n",
    "print(f\"最佳模型在验证集上的准确率: {best_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
